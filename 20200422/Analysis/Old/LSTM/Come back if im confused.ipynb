{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.712070Z",
     "start_time": "2019-08-11T17:00:36.111693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=iMIWee_PXl8\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.720195Z",
     "start_time": "2019-08-11T17:00:38.715793Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [[[(i+j)] for i in range(5)] for j in range(100)]\n",
    "target = [(i+5) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.732410Z",
     "start_time": "2019-08-11T17:00:38.723488Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=float)\n",
    "target = np.array(target, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.751570Z",
     "start_time": "2019-08-11T17:00:38.736033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.770052Z",
     "start_time": "2019-08-11T17:00:38.759672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.814324Z",
     "start_time": "2019-08-11T17:00:38.776988Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data,target,test_size=0.2, random_state = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:38.857834Z",
     "start_time": "2019-08-11T17:00:38.827701Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.257299Z",
     "start_time": "2019-08-11T17:00:38.860366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jackselbo/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(LSTM((1), batch_input_shape=(None,5,1), return_sequences=False))\n",
    "# model.add(LSTM((1), return_sequences=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.297799Z",
     "start_time": "2019-08-11T17:00:39.260244Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.312200Z",
     "start_time": "2019-08-11T17:00:39.299571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.442581Z",
     "start_time": "2019-08-11T17:00:39.314984Z"
    }
   },
   "outputs": [],
   "source": [
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.595518Z",
     "start_time": "2019-08-11T17:00:39.444709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGHBJREFUeJzt3X+Q3PV93/HnSwIlo9g+wDrbBOnusCs6ISWx8Q1J6iZDR9gVTI3SjpuKXhpiO7nJOGrrSdoJnetQh8zN+Me0oWlp0ithjM3VYLt1LDLyYEd2mplOIBwORgiCJVNOXEThYsi5GU0Lqt/9Y7/39Wq1e7rb72f3+2Nfj5mb3f3uZ/fz0Uff/b7383MVEZiZmQFsK7sAZmZWHQ4KZmaWc1AwM7Ocg4KZmeUcFMzMLOegYGZmOQcFMzPLOSiYmVnOQcHMzHIXlV2AXnbt2hVTU1NlF8PMrFYee+yxv4iI8X5fX9mgMDU1xdLSUtnFMDOrFUnLRV7v7iMzM8s5KJiZWc5BwczMcg4KZmaWc1AwM7Ocg4KZmeUcFKxyFo8tMnXnFNt+fRtTd06xeGyx7CKZjQwHhQHxha0/i8cWmX1wluW1ZYJgeW2Z2QdnXX9mQ5IkKEi6R9JLkp7s8bwk/Zakk5KekHRtinyryhe2/s0dnePMa2fOOXbmtTPMHZ0rqURmoyVVS+GTwP4Nnr8R2Jv9zQK/nSjfSvKFrX+n1k5t6bh9j1unlkKSoBARfwS8vEGSA8CnouVh4BJJl6fIu4p8YevfxNjElo5bi1unlsqwxhSuAJ5ve7ySHWskX9j6N79vnp0X7zzn2M6LdzK/b76kEtWDW6eWyrCCgroci/MSSbOSliQtra6uDqFYg+ELW/9mrplh4b0LTI5NIsTk2CQL711g5pqZsotWaW6dWirD2iV1BdjT9ng3cLozUUQsAAsA09PT5wWNuli/gM0dnePU2ikmxiaY3zfvC9smzVwz47raoomxCZbXzt8c061T26phBYXDwCFJ9wM/BqxFxAtDyrsUvrDZMM3vm2f2wdlzupDcOrV+JAkKkj4DXA/skrQC/GvgYoCI+B3gCHATcBI4A7w/Rb5m1uLWqaWiiGr20kxPT4d/ZMfMbGskPRYR0/2+3iuazcws56BgZmY5BwUzM8s5KJiZWc5BwczMcg4KZmaWc1AwM7Ocg4KZmeUcFMzMLOegYGZmOQcFMzPLOSiYmVnOQcHMzHIOCmZmlnNQMDOznIOCmZnlHBTMzCznoGBmZjkHBTMzyyUJCpL2S3pG0klJt3V5fkLS1yT9qaQnJN2UIl8zM0urcFCQtB24C7gRuBq4RdLVHcn+FfDZiHgHcBD4j0XzNTOz9FK0FK4DTkbEsxHxKnA/cKAjTQBvyO6PAacT5GtmZoldlOA9rgCeb3u8AvxYR5qPAF+W9E+AHwBuSJCvmZkllqKloC7HouPxLcAnI2I3cBPwaUnn5S1pVtKSpKXV1dUERTMzs61IERRWgD1tj3dzfvfQB4HPAkTEHwPfD+zqfKOIWIiI6YiYHh8fT1A0MzPbihRB4VFgr6QrJe2gNZB8uCPNKWAfgKQfohUU3BQwM6uYwkEhIs4Ch4CHgKdpzTI6LukOSTdnyX4V+EVJ3wA+A/x8RHR2MZmZWclSDDQTEUeAIx3Hbm+7/xTwrhR5mZnZ4HhFs5mZ5RwUzMws56BgZmY5BwUzM8s5KJiZWc5BwczMcg4KZmaWc1AwM7Ocg4KZmeUcFBpo8dgiU3dOse3XtzF15xSLxxbLLpKZ1USSbS6sOhaPLTL74CxnXjsDwPLaMrMPzgIwc81MmUUzsxpwS6Fh5o7O5QFh3ZnXzjB3dK6kEplZnTgoNMyptVNbOm5m1s5BoWEmxia2dNzMrJ2DQsPM75tn58U7zzm28+KdzO+bL6lEZlYnDgoNM3PNDAvvXWBybBIhJscmWXjvggeZzWxTVNUfQJueno6lpaWyi2FmViuSHouI6X5f75aCmZnlHBTMzCznoGBmZrkkQUHSfknPSDop6bYeaX5G0lOSjkv6LynyNTOztApvcyFpO3AX8G5gBXhU0uGIeKotzV7gXwLviohXJL2paL5mZpZeipbCdcDJiHg2Il4F7gcOdKT5ReCuiHgFICJeSpCvmVntVW0DyxRB4Qrg+bbHK9mxdlcBV0n6H5IelrS/2xtJmpW0JGlpdXU1QdGsDFU7yc2qan0Dy+W1ZYLIN7As8zOTIiioy7HOxQ8XAXuB64FbgLslXXLeiyIWImI6IqbHx8cTFM2GrYonuVlVVXEDyxRBYQXY0/Z4N3C6S5ovRsRrEfE/gWdoBQlrmCqe5GZVVcUNLFMEhUeBvZKulLQDOAgc7kjze8DfBpC0i1Z30rMJ8raKqeJJblZVVdzAsnBQiIizwCHgIeBp4LMRcVzSHZJuzpI9BHxb0lPA14B/ERHfLpq3VU8VT3KzqqriBpZJ1ilExJGIuCoi3hYR89mx2yPicHY/IuJXIuLqiLgmIu5Pka9VTxVPcrOqquIGlt4Qz5JbPLbI3NE5Tq2dYmJsgvl9896l1WxIim6I56BgZtYg3iXVLCGvsbBRV3ibC7OmWF9jsT6ldn2NBeDuLxsZbimYZbzGwsxBwSznNRZmDgpmOa+xMHNQMMt5jYWZg4JZLsVCIs9esrrzOgWzRDpnL0GrpVH2ClUbLV6nYFYRnr1kTeCgYI1SZveNZy9ZEzgoWGOU/QM/nr1kTeCgYI1RdveNZy9ZEzgoWGOU3X1TxW2QzbbKex9ZY0yMTbC8ttz1+LDMXDPjIGC15paCNYa7b8yKc1CwxnD3TX150V91ePGamZXKi/7SqsTiNUn7JT0j6aSk2zZI9z5JIanvAptZs5Q9a6yoprVyCg80S9oO3AW8G1gBHpV0OCKe6kj3euCfAo8UzdPMmqPsWWNFNPGHmVK0FK4DTkbEsxHxKnA/cKBLut8APg78nwR5mllD1HnRX91bOd2kCApXAM+3PV7JjuUkvQPYExG/v9EbSZqVtCRpaXV1NUHRzKzq6jxrrM6tnF5SBAV1OZaPXkvaBvwm8KsXeqOIWIiI6YiYHh8fT1A0M6u6Os8aq3Mrp5cUi9dWgD1tj3cDp9sevx74G8AfSgJ4C3BY0s0R4elFZlbbRX/z++a7zpyqQyunlxQthUeBvZKulLQDOAgcXn8yItYiYldETEXEFPAw4IBgZrVX51ZOL4VbChFxVtIh4CFgO3BPRByXdAewFBGHN34HM7P6qmsrp5ckex9FxBHgSMex23ukvT5FnmZmlp63uTCzkde0BWhFeJdUMxtpTVyAVoRbCmY20pq4AK0IBwUzG2lNXIBWhIOCmQGj26/exAVoRTgomFner768tkwQeb/6KASGOm+zMQgOCmY20v3qTVyAVoRnH9l5Fo8tMnd0jlNrp5gYm2B+3/zIfkBGxaj3qzdtAVoRbinYOUa5G2GUuV/d1jko2DlGuRthlLlf3dY5KNg5Rr0bYVS5X93WeUzBzjExNsHy2nLX49Zs7lc3aHhLYVTnXRfhbgSz0dbYoOAB0/64G8FstCkiLpyqBNPT07G01P/v8EzdOdW1G2RybJLnPvxcgZKZmVWXpMciYrrf1ze2peABUzOzrWtsUPC8azOzrWtsUPCAqZnZ1jU2KNR9wNQzp8ysDEkGmiXtB/4dsB24OyI+2vH8rwC/AJwFVoEPRMT5o8Btig4011nnL0FBq5VTp6BmZuUofaBZ0nbgLuBG4GrgFklXdyT7U2A6In4E+Dzw8aL5Npm3mjCzsqToProOOBkRz0bEq8D9wIH2BBHxtYhYv8o9DOxOkG9jeeaU2da4uzWdFEHhCuD5tscr2bFePgh8KUG+jeWZU1ZHZV2YvVA1rRRBQV2OdR2okPSzwDTwiR7Pz0pakrS0urqaoGj15JlTVjdlXpjd3ZpWiqCwAuxpe7wbON2ZSNINwBxwc0T8325vFBELETEdEdPj4+MJilZPdZ85ZaOnzAuzu1vTSrFL6qPAXklXAn8OHAT+UXsCSe8A/hOwPyJeSpBn43nHSquTMi/M3tk3rcIthYg4CxwCHgKeBj4bEccl3SHp5izZJ4DXAZ+T9Likw0XzNbPqKHMczN2taSVZvBYRRyLiqoh4W0TMZ8duj4jD2f0bIuLNEfH27O/mjd+xfJ7NYLZ5ZV6Y3d2aVmN3SS3Ci8fMtm7x2CJzR+c4tXaKibEJ5vfN+/NSgqKL1xwUuvC222ZWV6WvaG4iz2Yws1HloNCFF4+Z2ahyUOjCsxnMbFQ5KHTh2QxmNqo80Gxm1iAeaDYzs2QcFMzMLOegYGZmOQcFs4rw1ipWBSl2STWzgjq3Vln/PQLAs95sqNxSMKsA/1CMVYWDglkFeGsVqwoHBbMK8NYqVhUOCmYV4K1VrCocFMwqwFurWFV4mwszswbxNhdmZpZMkqAgab+kZySdlHRbl+e/T9ID2fOPSJpKka+ZmaVVOChI2g7cBdwIXA3cIunqjmQfBF6JiL8G/CbwsaL5mplZeilaCtcBJyPi2Yh4FbgfONCR5gBwb3b/88A+SUqQt5mZJZQiKFwBPN/2eCU71jVNRJwF1oA3JsjbzMwSShEUun3j75zStJk0SJqVtCRpaXV1NUHRzMxsK1IEhRVgT9vj3cDpXmkkXQSMAS93vlFELETEdERMj4+PJyiamZltRYqg8CiwV9KVknYAB4HDHWkOA7dm998HfDWqukDCrCyLizA1Bdu2tW4XvXW2DV/hrbMj4qykQ8BDwHbgnog4LukOYCkiDgO/C3xa0klaLYSDRfM1a5TFRZidhTPZTqnLy63HADNe1WzD4xXNZlUwNdUKBJ0mJ+G554ZdGqsxr2g2a4JTPbbI7nXcbEAcFMyqYKLHFtm9jpsNiIOCWRXMz8POc7fOZufO1nGzIXJQMKuCmRlYWGiNIUit24UFDzLb0Dko9OLpgTZsMzOtQeXvfrd164BgJSg8JbWRPD3QzEaUWwrdzM19LyCsO3OmddzMrMEcFLrx9ECzrXOXayM4KHTj6YFmW7Pe5bq8DBHf63IdVmBwQErGQaEbTw8025oyu1zLDkgN46DQTRWmB/qbj9VJmV2uHgNMynsfVVHn7CdotVQ8b92qqsy9m7Zta7UQOkmt6b0jxnsfNZG/+VjdlNnl6jHApJodFOraBePZT1Y3ZXa5egwwqeYuXqvzArSJie5NcX/zsSqbmSnns7We59xc64vTxEQrIFT9c15RzR1TqPP+9B5TMLM+eUyhlzp3wVRh9pOZjaTmBoW6Dz6VuTlaXcdizKyw5gYFDz71xwuBRpe/DBgFg4KkyyR9RdKJ7PbSLmneLumPJR2X9ISkf1gkz01zF0x/PB12NPnLgGUKDTRL+jjwckR8VNJtwKUR8Wsdaa4CIiJOSPpB4DHghyLiLzd675FevFYmLwQaTXWemJHC4mJjZi+VPdB8ALg3u38v8NOdCSLimxFxIrt/GngJGC+Yrw1K3cdirD91nphRlFtJ5ygaFN4cES8AZLdv2iixpOuAHcC3CuZrg+KxmNE0yl8G3GV6jgsGBUl/IOnJLn8HtpKRpMuBTwPvj4iu/RCSZiUtSVpaXV3dyttbKh6LGU2j/GVglFtJ3URE33/AM8Dl2f3LgWd6pHsD8HXgH2z2vd/5zneGmQ3RffdFTE5GSK3b++4ru0TDMTkZ0eo4OvdvcnJzr69YvQFLUeC6XrT76DBwa3b/VuCLnQkk7QC+AHwqIj5XMD8zG5RRXRtTpJXUxPGIIhEFeCNwFDiR3V6WHZ8G7s7u/yzwGvB429/bL/TebimYjYj77ovYufPcb+k7dw73G3e/3/aLtjIGgIIthebufWRm9VDn6bAVnMJd9pRUs2rxqtz6qfNAbwNnbTkoWHNUoX/XQWnr6nxhbeCsLQcFa46y55tXISjVUZ0vrA2cwu2gYM2RohuiyDf9soNSXdX9wlrmrK0B8ECzNUfRAcuiP25UwUFHGz0eaLbqKatfvWg3RNFv+nXuGzfLOChYWmX2qxfthija/VTnvnErT8UmJ7j7yNKq85zzFGVv0BbMNgQD+D32ot1HDgqWVp371QfwATXb0AC+RHlMwc5XZnO0zv3qdZ8FY/VTwYV7DgpNU/Zc+br3qzdseqFVXAW/RDkoNE3Zc+X9bdts8yr4JcpjCk1T5z59s1GUeHJC0TGFi/rO2appYqL7wFUd+vTNRtHMTKVa0u4+apoKNkfNrD4cFAalrBlATejTr9hintpwvVkCHlMYBM9375/rrj+uN8t48VoV1XlVb9lcd/1xvVnGi9eqqIILUmrDddcf15slUigoSLpM0lcknchuL90g7Rsk/bmk/1Akz1qo4IKU2nDd9cf1ZokUbSncBhyNiL3A0exxL78B/PeC+dWDZwD1z3XXH9ebJVI0KBwA7s3u3wv8dLdEkt4JvBn4csH86qEJM4DK4rrrj+vNEik00CzpLyPikrbHr0TEpR1ptgFfBf4xsA+YjohDF3rvWg80m5mVZOArmiX9AfCWLk9tdjOdDwFHIuJ5SRfKaxaYBZhwX6iZ2dBdMChExA29npP0oqTLI+IFSZcDL3VJ9hPAT0r6EPA6YIekv4qI88YfImIBWIBWS2Gz/wgzM0uj6N5Hh4FbgY9mt1/sTBAReaempJ+n1X200YC0mZmVpOhA80eBd0s6Abw7e4ykaUl3Fy2cmZkNl1c0m5k1iFc0m5lZMg4KZmaWq2z3kaRVoMsOX33ZBfxFovdKzWXrT5XLBtUun8vWvyqXb71skxEx3u+bVDYopCRpqUgf2yC5bP2pctmg2uVz2fpX5fKlKpu7j8zMLOegYGZmuVEJCgtlF2ADLlt/qlw2qHb5XLb+Vbl8Sco2EmMKZma2OaPSUjAzs01oTFCQtF/SM5JOSjpvbyVJ3yfpgez5RyRNDbFseyR9TdLTko5L+mdd0lwvaU3S49nf7UMs33OSjmX5nreMXC2/ldXdE5KuHVK5/npbfTwu6TuSPtyRZqj1JukeSS9JerLt2KZ+gVDSrVmaE5JuHVLZPiHpz7L/ty9IuqTHazc8BwZUto9kv8a4/n93U4/XbvjZHlDZHmgr13OSHu/x2kHXW9drx0DPuYio/R+wHfgW8FZgB/AN4OqONB8Cfie7fxB4YIjluxy4Nrv/euCbXcp3PfD7JdXfc8CuDZ6/CfgSIODHgUdK+j/+X7TmYJdWb8BPAdcCT7Yd+zhwW3b/NuBjXV53GfBsdntpdv/SIZTtPcBF2f2PdSvbZs6BAZXtI8A/38T/+4af7UGUreP5fwPcXlK9db12DPKca0pL4TrgZEQ8GxGvAvfT+lW4du2/Evd5YJ8u9AMPiUTECxHx9ez+/waeBq4YRt6JHAA+FS0PA5dkW6UP0z7gWxGRakFjXyLij4CXOw5v5hcI/w7wlYh4OSJeAb4C7B902SLiyxFxNnv4MLA7ZZ6b1aPeNmMzn+2BlS27RvwM8JmUeW7WBteOgZ1zTQkKVwDPtz1e4fyLbp4m+5CsAW8cSunaZN1W7wAe6fL0T0j6hqQvSfrhIRYrgC9LekytHzrqtJn6HbSD9P5gllVv694cES9A60MMvKlLmirU4Qdotfi6udA5MCiHsq6te3p0gZRdbz8JvBgRJ3o8P7R667h2DOyca0pQ6PaNv3Na1WbSDJSk1wH/FfhwRHyn4+mv0+oa+VHg3wO/N8SivSsirgVuBH5Z0k91PF9q3UnaAdwMfK7L02XW21aUXYdzwFlgsUeSC50Dg/DbwNuAtwMv0Oqm6VT25/YWNm4lDKXeLnDt6PmyLscuWHdNCQorwJ62x7uB073SSLoIGKO/5mxfJF1M6z91MSL+W+fzEfGdiPir7P4R4GJJu4ZRtog4nd2+BHyBVpO93Wbqd5BuBL4eES92PlFmvbV5cb07Tb1/gbC0OswGGP8uMBNZZ3OnTZwDyUXEixHx/yLiu8B/7pFnmfV2EfD3gQd6pRlGvfW4dgzsnGtKUHgU2Cvpyuxb5UFavwrXbv1X4gDeB3y11wcktaxf8neBpyPi3/ZI85b1MQ5J19H6v/n2EMr2A5Jev36f1sDkkx3JDgM/p5YfB9bWm65D0vPbWln11qH93Or6C4TAQ8B7JF2adZO8Jzs2UJL2A78G3BwRZ3qk2cw5MIiytY9L/b0eeW7msz0oNwB/FhEr3Z4cRr1tcO0Y3Dk3qFHzYf/RmiHzTVozFeayY3fQ+jAAfD+t7oeTwJ8Abx1i2f4WrWbbE8Dj2d9NwC8Bv5SlOQQcpzW74mHgbw6pbG/N8vxGlv963bWXTcBdWd0eo/WTqsOqu520LvJjbcdKqzdawekF4DVa38Q+SGts6ihwIru9LEs7Ddzd9toPZOffSeD9QyrbSVr9yuvn3foMvB8Ejmx0DgyhbJ/OzqcnaF3kLu8sW/b4vM/2oMuWHf/k+nnWlnbY9dbr2jGwc84rms3MLNeU7iMzM0vAQcHMzHIOCmZmlnNQMDOznIOCmZnlHBTMzCznoGBmZjkHBTMzy/1/qufsmgz7ymoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.658673Z",
     "start_time": "2019-08-11T17:00:39.597812Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:39.665425Z",
     "start_time": "2019-08-11T17:00:39.661354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:49.902196Z",
     "start_time": "2019-08-11T17:00:39.667872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jackselbo/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.8257 - acc: 0.0000e+00 - val_loss: 0.6777 - val_acc: 0.0000e+00\n",
      "Epoch 2/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.8224 - acc: 0.0000e+00 - val_loss: 0.6745 - val_acc: 0.0000e+00\n",
      "Epoch 3/400\n",
      "80/80 [==============================] - 0s 501us/step - loss: 0.8192 - acc: 0.0000e+00 - val_loss: 0.6713 - val_acc: 0.0000e+00\n",
      "Epoch 4/400\n",
      "80/80 [==============================] - 0s 463us/step - loss: 0.8159 - acc: 0.0000e+00 - val_loss: 0.6682 - val_acc: 0.0000e+00\n",
      "Epoch 5/400\n",
      "80/80 [==============================] - 0s 376us/step - loss: 0.8127 - acc: 0.0000e+00 - val_loss: 0.6650 - val_acc: 0.0000e+00\n",
      "Epoch 6/400\n",
      "80/80 [==============================] - 0s 360us/step - loss: 0.8095 - acc: 0.0000e+00 - val_loss: 0.6619 - val_acc: 0.0000e+00\n",
      "Epoch 7/400\n",
      "80/80 [==============================] - 0s 410us/step - loss: 0.8063 - acc: 0.0000e+00 - val_loss: 0.6588 - val_acc: 0.0000e+00\n",
      "Epoch 8/400\n",
      "80/80 [==============================] - 0s 335us/step - loss: 0.8031 - acc: 0.0000e+00 - val_loss: 0.6557 - val_acc: 0.0000e+00\n",
      "Epoch 9/400\n",
      "80/80 [==============================] - 0s 269us/step - loss: 0.7999 - acc: 0.0000e+00 - val_loss: 0.6526 - val_acc: 0.0000e+00\n",
      "Epoch 10/400\n",
      "80/80 [==============================] - 0s 373us/step - loss: 0.7968 - acc: 0.0000e+00 - val_loss: 0.6496 - val_acc: 0.0000e+00\n",
      "Epoch 11/400\n",
      "80/80 [==============================] - 0s 270us/step - loss: 0.7936 - acc: 0.0000e+00 - val_loss: 0.6465 - val_acc: 0.0000e+00\n",
      "Epoch 12/400\n",
      "80/80 [==============================] - 0s 323us/step - loss: 0.7905 - acc: 0.0000e+00 - val_loss: 0.6435 - val_acc: 0.0000e+00\n",
      "Epoch 13/400\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.7874 - acc: 0.0000e+00 - val_loss: 0.6405 - val_acc: 0.0000e+00\n",
      "Epoch 14/400\n",
      "80/80 [==============================] - 0s 273us/step - loss: 0.7843 - acc: 0.0000e+00 - val_loss: 0.6376 - val_acc: 0.0000e+00\n",
      "Epoch 15/400\n",
      "80/80 [==============================] - 0s 290us/step - loss: 0.7813 - acc: 0.0000e+00 - val_loss: 0.6346 - val_acc: 0.0000e+00\n",
      "Epoch 16/400\n",
      "80/80 [==============================] - 0s 302us/step - loss: 0.7782 - acc: 0.0000e+00 - val_loss: 0.6317 - val_acc: 0.0000e+00\n",
      "Epoch 17/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.7753 - acc: 0.0000e+00 - val_loss: 0.6288 - val_acc: 0.0000e+00\n",
      "Epoch 18/400\n",
      "80/80 [==============================] - 0s 367us/step - loss: 0.7723 - acc: 0.0000e+00 - val_loss: 0.6259 - val_acc: 0.0000e+00\n",
      "Epoch 19/400\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.7693 - acc: 0.0000e+00 - val_loss: 0.6231 - val_acc: 0.0000e+00\n",
      "Epoch 20/400\n",
      "80/80 [==============================] - 0s 348us/step - loss: 0.7664 - acc: 0.0000e+00 - val_loss: 0.6203 - val_acc: 0.0000e+00\n",
      "Epoch 21/400\n",
      "80/80 [==============================] - 0s 294us/step - loss: 0.7635 - acc: 0.0000e+00 - val_loss: 0.6175 - val_acc: 0.0000e+00\n",
      "Epoch 22/400\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.7606 - acc: 0.0000e+00 - val_loss: 0.6147 - val_acc: 0.0000e+00\n",
      "Epoch 23/400\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.7578 - acc: 0.0000e+00 - val_loss: 0.6120 - val_acc: 0.0000e+00\n",
      "Epoch 24/400\n",
      "80/80 [==============================] - 0s 252us/step - loss: 0.7549 - acc: 0.0000e+00 - val_loss: 0.6093 - val_acc: 0.0000e+00\n",
      "Epoch 25/400\n",
      "80/80 [==============================] - 0s 278us/step - loss: 0.7521 - acc: 0.0000e+00 - val_loss: 0.6066 - val_acc: 0.0000e+00\n",
      "Epoch 26/400\n",
      "80/80 [==============================] - 0s 353us/step - loss: 0.7493 - acc: 0.0000e+00 - val_loss: 0.6039 - val_acc: 0.0000e+00\n",
      "Epoch 27/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.7466 - acc: 0.0000e+00 - val_loss: 0.6013 - val_acc: 0.0000e+00\n",
      "Epoch 28/400\n",
      "80/80 [==============================] - 0s 265us/step - loss: 0.7438 - acc: 0.0000e+00 - val_loss: 0.5986 - val_acc: 0.0000e+00\n",
      "Epoch 29/400\n",
      "80/80 [==============================] - 0s 296us/step - loss: 0.7411 - acc: 0.0000e+00 - val_loss: 0.5960 - val_acc: 0.0000e+00\n",
      "Epoch 30/400\n",
      "80/80 [==============================] - 0s 291us/step - loss: 0.7384 - acc: 0.0000e+00 - val_loss: 0.5935 - val_acc: 0.0000e+00\n",
      "Epoch 31/400\n",
      "80/80 [==============================] - 0s 268us/step - loss: 0.7357 - acc: 0.0000e+00 - val_loss: 0.5909 - val_acc: 0.0000e+00\n",
      "Epoch 32/400\n",
      "80/80 [==============================] - 0s 254us/step - loss: 0.7331 - acc: 0.0000e+00 - val_loss: 0.5884 - val_acc: 0.0000e+00\n",
      "Epoch 33/400\n",
      "80/80 [==============================] - 0s 285us/step - loss: 0.7305 - acc: 0.0000e+00 - val_loss: 0.5858 - val_acc: 0.0000e+00\n",
      "Epoch 34/400\n",
      "80/80 [==============================] - 0s 295us/step - loss: 0.7278 - acc: 0.0000e+00 - val_loss: 0.5834 - val_acc: 0.0000e+00\n",
      "Epoch 35/400\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.7252 - acc: 0.0000e+00 - val_loss: 0.5809 - val_acc: 0.0000e+00\n",
      "Epoch 36/400\n",
      "80/80 [==============================] - 0s 241us/step - loss: 0.7227 - acc: 0.0000e+00 - val_loss: 0.5784 - val_acc: 0.0000e+00\n",
      "Epoch 37/400\n",
      "80/80 [==============================] - 0s 277us/step - loss: 0.7201 - acc: 0.0000e+00 - val_loss: 0.5760 - val_acc: 0.0000e+00\n",
      "Epoch 38/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.7176 - acc: 0.0000e+00 - val_loss: 0.5736 - val_acc: 0.0000e+00\n",
      "Epoch 39/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.7151 - acc: 0.0000e+00 - val_loss: 0.5713 - val_acc: 0.0000e+00\n",
      "Epoch 40/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.7127 - acc: 0.0000e+00 - val_loss: 0.5689 - val_acc: 0.0000e+00\n",
      "Epoch 41/400\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.7103 - acc: 0.0000e+00 - val_loss: 0.5666 - val_acc: 0.0000e+00\n",
      "Epoch 42/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.7079 - acc: 0.0000e+00 - val_loss: 0.5643 - val_acc: 0.0000e+00\n",
      "Epoch 43/400\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.7055 - acc: 0.0000e+00 - val_loss: 0.5620 - val_acc: 0.0000e+00\n",
      "Epoch 44/400\n",
      "80/80 [==============================] - 0s 216us/step - loss: 0.7032 - acc: 0.0000e+00 - val_loss: 0.5598 - val_acc: 0.0000e+00\n",
      "Epoch 45/400\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.7009 - acc: 0.0000e+00 - val_loss: 0.5575 - val_acc: 0.0000e+00\n",
      "Epoch 46/400\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.6986 - acc: 0.0000e+00 - val_loss: 0.5553 - val_acc: 0.0000e+00\n",
      "Epoch 47/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.6963 - acc: 0.0000e+00 - val_loss: 0.5532 - val_acc: 0.0000e+00\n",
      "Epoch 48/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.6941 - acc: 0.0000e+00 - val_loss: 0.5510 - val_acc: 0.0000e+00\n",
      "Epoch 49/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.6919 - acc: 0.0000e+00 - val_loss: 0.5489 - val_acc: 0.0000e+00\n",
      "Epoch 50/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.6897 - acc: 0.0000e+00 - val_loss: 0.5468 - val_acc: 0.0000e+00\n",
      "Epoch 51/400\n",
      "80/80 [==============================] - 0s 211us/step - loss: 0.6876 - acc: 0.0000e+00 - val_loss: 0.5447 - val_acc: 0.0000e+00\n",
      "Epoch 52/400\n",
      "80/80 [==============================] - 0s 197us/step - loss: 0.6855 - acc: 0.0000e+00 - val_loss: 0.5427 - val_acc: 0.0000e+00\n",
      "Epoch 53/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.6833 - acc: 0.0000e+00 - val_loss: 0.5406 - val_acc: 0.0000e+00\n",
      "Epoch 54/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.6813 - acc: 0.0000e+00 - val_loss: 0.5386 - val_acc: 0.0000e+00\n",
      "Epoch 55/400\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.6792 - acc: 0.0000e+00 - val_loss: 0.5366 - val_acc: 0.0000e+00\n",
      "Epoch 56/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 221us/step - loss: 0.6772 - acc: 0.0000e+00 - val_loss: 0.5346 - val_acc: 0.0000e+00\n",
      "Epoch 57/400\n",
      "80/80 [==============================] - 0s 259us/step - loss: 0.6752 - acc: 0.0000e+00 - val_loss: 0.5327 - val_acc: 0.0000e+00\n",
      "Epoch 58/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.6731 - acc: 0.0000e+00 - val_loss: 0.5308 - val_acc: 0.0000e+00\n",
      "Epoch 59/400\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.6712 - acc: 0.0000e+00 - val_loss: 0.5288 - val_acc: 0.0000e+00\n",
      "Epoch 60/400\n",
      "80/80 [==============================] - 0s 291us/step - loss: 0.6692 - acc: 0.0000e+00 - val_loss: 0.5269 - val_acc: 0.0000e+00\n",
      "Epoch 61/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.6672 - acc: 0.0000e+00 - val_loss: 0.5251 - val_acc: 0.0000e+00\n",
      "Epoch 62/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.6653 - acc: 0.0000e+00 - val_loss: 0.5233 - val_acc: 0.0000e+00\n",
      "Epoch 63/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.6633 - acc: 0.0000e+00 - val_loss: 0.5216 - val_acc: 0.0000e+00\n",
      "Epoch 64/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.6614 - acc: 0.0000e+00 - val_loss: 0.5198 - val_acc: 0.0000e+00\n",
      "Epoch 65/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.6595 - acc: 0.0000e+00 - val_loss: 0.5181 - val_acc: 0.0000e+00\n",
      "Epoch 66/400\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.6576 - acc: 0.0000e+00 - val_loss: 0.5164 - val_acc: 0.0000e+00\n",
      "Epoch 67/400\n",
      "80/80 [==============================] - 0s 263us/step - loss: 0.6557 - acc: 0.0000e+00 - val_loss: 0.5147 - val_acc: 0.0000e+00\n",
      "Epoch 68/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.6539 - acc: 0.0000e+00 - val_loss: 0.5130 - val_acc: 0.0000e+00\n",
      "Epoch 69/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.6520 - acc: 0.0000e+00 - val_loss: 0.5113 - val_acc: 0.0000e+00\n",
      "Epoch 70/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.6502 - acc: 0.0000e+00 - val_loss: 0.5096 - val_acc: 0.0000e+00\n",
      "Epoch 71/400\n",
      "80/80 [==============================] - 0s 279us/step - loss: 0.6484 - acc: 0.0000e+00 - val_loss: 0.5080 - val_acc: 0.0000e+00\n",
      "Epoch 72/400\n",
      "80/80 [==============================] - 0s 252us/step - loss: 0.6466 - acc: 0.0000e+00 - val_loss: 0.5063 - val_acc: 0.0000e+00\n",
      "Epoch 73/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.6448 - acc: 0.0000e+00 - val_loss: 0.5047 - val_acc: 0.0000e+00\n",
      "Epoch 74/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.6431 - acc: 0.0000e+00 - val_loss: 0.5031 - val_acc: 0.0000e+00\n",
      "Epoch 75/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.6413 - acc: 0.0000e+00 - val_loss: 0.5015 - val_acc: 0.0000e+00\n",
      "Epoch 76/400\n",
      "80/80 [==============================] - 0s 272us/step - loss: 0.6396 - acc: 0.0000e+00 - val_loss: 0.4999 - val_acc: 0.0000e+00\n",
      "Epoch 77/400\n",
      "80/80 [==============================] - 0s 255us/step - loss: 0.6379 - acc: 0.0000e+00 - val_loss: 0.4984 - val_acc: 0.0000e+00\n",
      "Epoch 78/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.6363 - acc: 0.0000e+00 - val_loss: 0.4968 - val_acc: 0.0000e+00\n",
      "Epoch 79/400\n",
      "80/80 [==============================] - 0s 207us/step - loss: 0.6346 - acc: 0.0000e+00 - val_loss: 0.4953 - val_acc: 0.0000e+00\n",
      "Epoch 80/400\n",
      "80/80 [==============================] - 0s 289us/step - loss: 0.6330 - acc: 0.0000e+00 - val_loss: 0.4938 - val_acc: 0.0000e+00\n",
      "Epoch 81/400\n",
      "80/80 [==============================] - 0s 241us/step - loss: 0.6314 - acc: 0.0000e+00 - val_loss: 0.4923 - val_acc: 0.0000e+00\n",
      "Epoch 82/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.6297 - acc: 0.0000e+00 - val_loss: 0.4908 - val_acc: 0.0000e+00\n",
      "Epoch 83/400\n",
      "80/80 [==============================] - 0s 246us/step - loss: 0.6281 - acc: 0.0000e+00 - val_loss: 0.4893 - val_acc: 0.0000e+00\n",
      "Epoch 84/400\n",
      "80/80 [==============================] - 0s 256us/step - loss: 0.6266 - acc: 0.0000e+00 - val_loss: 0.4879 - val_acc: 0.0000e+00\n",
      "Epoch 85/400\n",
      "80/80 [==============================] - 0s 247us/step - loss: 0.6250 - acc: 0.0000e+00 - val_loss: 0.4864 - val_acc: 0.0000e+00\n",
      "Epoch 86/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.6234 - acc: 0.0000e+00 - val_loss: 0.4850 - val_acc: 0.0000e+00\n",
      "Epoch 87/400\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.6219 - acc: 0.0000e+00 - val_loss: 0.4835 - val_acc: 0.0000e+00\n",
      "Epoch 88/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.6204 - acc: 0.0000e+00 - val_loss: 0.4821 - val_acc: 0.0000e+00\n",
      "Epoch 89/400\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.6189 - acc: 0.0000e+00 - val_loss: 0.4807 - val_acc: 0.0000e+00\n",
      "Epoch 90/400\n",
      "80/80 [==============================] - 0s 392us/step - loss: 0.6175 - acc: 0.0000e+00 - val_loss: 0.4794 - val_acc: 0.0000e+00\n",
      "Epoch 91/400\n",
      "80/80 [==============================] - 0s 277us/step - loss: 0.6160 - acc: 0.0000e+00 - val_loss: 0.4780 - val_acc: 0.0000e+00\n",
      "Epoch 92/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.6146 - acc: 0.0000e+00 - val_loss: 0.4766 - val_acc: 0.0000e+00\n",
      "Epoch 93/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.6131 - acc: 0.0000e+00 - val_loss: 0.4753 - val_acc: 0.0000e+00\n",
      "Epoch 94/400\n",
      "80/80 [==============================] - 0s 248us/step - loss: 0.6117 - acc: 0.0000e+00 - val_loss: 0.4739 - val_acc: 0.0000e+00\n",
      "Epoch 95/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.6103 - acc: 0.0000e+00 - val_loss: 0.4726 - val_acc: 0.0000e+00\n",
      "Epoch 96/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.6089 - acc: 0.0000e+00 - val_loss: 0.4713 - val_acc: 0.0000e+00\n",
      "Epoch 97/400\n",
      "80/80 [==============================] - 0s 204us/step - loss: 0.6074 - acc: 0.0000e+00 - val_loss: 0.4700 - val_acc: 0.0000e+00\n",
      "Epoch 98/400\n",
      "80/80 [==============================] - 0s 208us/step - loss: 0.6061 - acc: 0.0000e+00 - val_loss: 0.4686 - val_acc: 0.0000e+00\n",
      "Epoch 99/400\n",
      "80/80 [==============================] - 0s 251us/step - loss: 0.6047 - acc: 0.0000e+00 - val_loss: 0.4673 - val_acc: 0.0000e+00\n",
      "Epoch 100/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.6034 - acc: 0.0000e+00 - val_loss: 0.4661 - val_acc: 0.0000e+00\n",
      "Epoch 101/400\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.6020 - acc: 0.0000e+00 - val_loss: 0.4648 - val_acc: 0.0000e+00\n",
      "Epoch 102/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.6007 - acc: 0.0000e+00 - val_loss: 0.4635 - val_acc: 0.0000e+00\n",
      "Epoch 103/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.5994 - acc: 0.0000e+00 - val_loss: 0.4623 - val_acc: 0.0000e+00\n",
      "Epoch 104/400\n",
      "80/80 [==============================] - 0s 253us/step - loss: 0.5981 - acc: 0.0000e+00 - val_loss: 0.4610 - val_acc: 0.0000e+00\n",
      "Epoch 105/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.5968 - acc: 0.0000e+00 - val_loss: 0.4598 - val_acc: 0.0000e+00\n",
      "Epoch 106/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5955 - acc: 0.0000e+00 - val_loss: 0.4586 - val_acc: 0.0000e+00\n",
      "Epoch 107/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.5943 - acc: 0.0000e+00 - val_loss: 0.4573 - val_acc: 0.0000e+00\n",
      "Epoch 108/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.5930 - acc: 0.0000e+00 - val_loss: 0.4561 - val_acc: 0.0000e+00\n",
      "Epoch 109/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.5917 - acc: 0.0000e+00 - val_loss: 0.4549 - val_acc: 0.0000e+00\n",
      "Epoch 110/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.5905 - acc: 0.0000e+00 - val_loss: 0.4537 - val_acc: 0.0000e+00\n",
      "Epoch 111/400\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.5892 - acc: 0.0000e+00 - val_loss: 0.4525 - val_acc: 0.0000e+00\n",
      "Epoch 112/400\n",
      "80/80 [==============================] - 0s 329us/step - loss: 0.5880 - acc: 0.0000e+00 - val_loss: 0.4513 - val_acc: 0.0000e+00\n",
      "Epoch 113/400\n",
      "80/80 [==============================] - 0s 278us/step - loss: 0.5868 - acc: 0.0000e+00 - val_loss: 0.4501 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.5856 - acc: 0.0000e+00 - val_loss: 0.4489 - val_acc: 0.0000e+00\n",
      "Epoch 115/400\n",
      "80/80 [==============================] - 0s 272us/step - loss: 0.5844 - acc: 0.0000e+00 - val_loss: 0.4477 - val_acc: 0.0000e+00\n",
      "Epoch 116/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5832 - acc: 0.0000e+00 - val_loss: 0.4466 - val_acc: 0.0000e+00\n",
      "Epoch 117/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.5820 - acc: 0.0000e+00 - val_loss: 0.4454 - val_acc: 0.0000e+00\n",
      "Epoch 118/400\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.5809 - acc: 0.0000e+00 - val_loss: 0.4443 - val_acc: 0.0000e+00\n",
      "Epoch 119/400\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5797 - acc: 0.0000e+00 - val_loss: 0.4432 - val_acc: 0.0000e+00\n",
      "Epoch 120/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.5786 - acc: 0.0000e+00 - val_loss: 0.4420 - val_acc: 0.0000e+00\n",
      "Epoch 121/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.5774 - acc: 0.0000e+00 - val_loss: 0.4409 - val_acc: 0.0000e+00\n",
      "Epoch 122/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.5763 - acc: 0.0000e+00 - val_loss: 0.4398 - val_acc: 0.0000e+00\n",
      "Epoch 123/400\n",
      "80/80 [==============================] - 0s 204us/step - loss: 0.5751 - acc: 0.0000e+00 - val_loss: 0.4386 - val_acc: 0.0000e+00\n",
      "Epoch 124/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.5740 - acc: 0.0000e+00 - val_loss: 0.4375 - val_acc: 0.0000e+00\n",
      "Epoch 125/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.5729 - acc: 0.0000e+00 - val_loss: 0.4364 - val_acc: 0.0000e+00\n",
      "Epoch 126/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.5718 - acc: 0.0000e+00 - val_loss: 0.4353 - val_acc: 0.0000e+00\n",
      "Epoch 127/400\n",
      "80/80 [==============================] - 0s 272us/step - loss: 0.5707 - acc: 0.0000e+00 - val_loss: 0.4342 - val_acc: 0.0000e+00\n",
      "Epoch 128/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.5696 - acc: 0.0000e+00 - val_loss: 0.4331 - val_acc: 0.0000e+00\n",
      "Epoch 129/400\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.5685 - acc: 0.0000e+00 - val_loss: 0.4320 - val_acc: 0.0000e+00\n",
      "Epoch 130/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.5674 - acc: 0.0000e+00 - val_loss: 0.4309 - val_acc: 0.0000e+00\n",
      "Epoch 131/400\n",
      "80/80 [==============================] - 0s 284us/step - loss: 0.5664 - acc: 0.0000e+00 - val_loss: 0.4298 - val_acc: 0.0000e+00\n",
      "Epoch 132/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.5654 - acc: 0.0000e+00 - val_loss: 0.4287 - val_acc: 0.0000e+00\n",
      "Epoch 133/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.5643 - acc: 0.0000e+00 - val_loss: 0.4277 - val_acc: 0.0000e+00\n",
      "Epoch 134/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.5633 - acc: 0.0000e+00 - val_loss: 0.4266 - val_acc: 0.0000e+00\n",
      "Epoch 135/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.5623 - acc: 0.0000e+00 - val_loss: 0.4256 - val_acc: 0.0000e+00\n",
      "Epoch 136/400\n",
      "80/80 [==============================] - 0s 621us/step - loss: 0.5612 - acc: 0.0000e+00 - val_loss: 0.4246 - val_acc: 0.0000e+00\n",
      "Epoch 137/400\n",
      "80/80 [==============================] - 0s 264us/step - loss: 0.5602 - acc: 0.0000e+00 - val_loss: 0.4235 - val_acc: 0.0000e+00\n",
      "Epoch 138/400\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.5592 - acc: 0.0000e+00 - val_loss: 0.4225 - val_acc: 0.0000e+00\n",
      "Epoch 139/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.5582 - acc: 0.0000e+00 - val_loss: 0.4214 - val_acc: 0.0000e+00\n",
      "Epoch 140/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5572 - acc: 0.0000e+00 - val_loss: 0.4204 - val_acc: 0.0000e+00\n",
      "Epoch 141/400\n",
      "80/80 [==============================] - 0s 271us/step - loss: 0.5562 - acc: 0.0000e+00 - val_loss: 0.4193 - val_acc: 0.0000e+00\n",
      "Epoch 142/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.5551 - acc: 0.0000e+00 - val_loss: 0.4183 - val_acc: 0.0000e+00\n",
      "Epoch 143/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.5542 - acc: 0.0000e+00 - val_loss: 0.4172 - val_acc: 0.0000e+00\n",
      "Epoch 144/400\n",
      "80/80 [==============================] - 0s 204us/step - loss: 0.5532 - acc: 0.0000e+00 - val_loss: 0.4162 - val_acc: 0.0000e+00\n",
      "Epoch 145/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.5523 - acc: 0.0000e+00 - val_loss: 0.4152 - val_acc: 0.0000e+00\n",
      "Epoch 146/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.5513 - acc: 0.0000e+00 - val_loss: 0.4142 - val_acc: 0.0000e+00\n",
      "Epoch 147/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.5503 - acc: 0.0000e+00 - val_loss: 0.4132 - val_acc: 0.0000e+00\n",
      "Epoch 148/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.5494 - acc: 0.0000e+00 - val_loss: 0.4122 - val_acc: 0.0000e+00\n",
      "Epoch 149/400\n",
      "80/80 [==============================] - 0s 180us/step - loss: 0.5484 - acc: 0.0000e+00 - val_loss: 0.4111 - val_acc: 0.0000e+00\n",
      "Epoch 150/400\n",
      "80/80 [==============================] - 0s 207us/step - loss: 0.5475 - acc: 0.0000e+00 - val_loss: 0.4101 - val_acc: 0.0000e+00\n",
      "Epoch 151/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.5465 - acc: 0.0000e+00 - val_loss: 0.4091 - val_acc: 0.0000e+00\n",
      "Epoch 152/400\n",
      "80/80 [==============================] - 0s 334us/step - loss: 0.5456 - acc: 0.0000e+00 - val_loss: 0.4081 - val_acc: 0.0000e+00\n",
      "Epoch 153/400\n",
      "80/80 [==============================] - 0s 269us/step - loss: 0.5446 - acc: 0.0000e+00 - val_loss: 0.4071 - val_acc: 0.0000e+00\n",
      "Epoch 154/400\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.5437 - acc: 0.0000e+00 - val_loss: 0.4061 - val_acc: 0.0000e+00\n",
      "Epoch 155/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.5427 - acc: 0.0000e+00 - val_loss: 0.4051 - val_acc: 0.0000e+00\n",
      "Epoch 156/400\n",
      "80/80 [==============================] - 0s 258us/step - loss: 0.5418 - acc: 0.0000e+00 - val_loss: 0.4041 - val_acc: 0.0000e+00\n",
      "Epoch 157/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.5408 - acc: 0.0000e+00 - val_loss: 0.4031 - val_acc: 0.0000e+00\n",
      "Epoch 158/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.5399 - acc: 0.0000e+00 - val_loss: 0.4021 - val_acc: 0.0000e+00\n",
      "Epoch 159/400\n",
      "80/80 [==============================] - 0s 276us/step - loss: 0.5390 - acc: 0.0000e+00 - val_loss: 0.4010 - val_acc: 0.0000e+00\n",
      "Epoch 160/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.5381 - acc: 0.0000e+00 - val_loss: 0.4000 - val_acc: 0.0000e+00\n",
      "Epoch 161/400\n",
      "80/80 [==============================] - 0s 247us/step - loss: 0.5371 - acc: 0.0000e+00 - val_loss: 0.3990 - val_acc: 0.0000e+00\n",
      "Epoch 162/400\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.5362 - acc: 0.0000e+00 - val_loss: 0.3980 - val_acc: 0.0000e+00\n",
      "Epoch 163/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.5353 - acc: 0.0000e+00 - val_loss: 0.3970 - val_acc: 0.0000e+00\n",
      "Epoch 164/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.5344 - acc: 0.0000e+00 - val_loss: 0.3960 - val_acc: 0.0000e+00\n",
      "Epoch 165/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.5335 - acc: 0.0000e+00 - val_loss: 0.3949 - val_acc: 0.0000e+00\n",
      "Epoch 166/400\n",
      "80/80 [==============================] - 0s 254us/step - loss: 0.5325 - acc: 0.0000e+00 - val_loss: 0.3939 - val_acc: 0.0000e+00\n",
      "Epoch 167/400\n",
      "80/80 [==============================] - 0s 254us/step - loss: 0.5317 - acc: 0.0000e+00 - val_loss: 0.3929 - val_acc: 0.0000e+00\n",
      "Epoch 168/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.5307 - acc: 0.0000e+00 - val_loss: 0.3919 - val_acc: 0.0000e+00\n",
      "Epoch 169/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.5298 - acc: 0.0000e+00 - val_loss: 0.3909 - val_acc: 0.0000e+00\n",
      "Epoch 170/400\n",
      "80/80 [==============================] - 0s 208us/step - loss: 0.5289 - acc: 0.0000e+00 - val_loss: 0.3900 - val_acc: 0.0000e+00\n",
      "Epoch 171/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 215us/step - loss: 0.5280 - acc: 0.0000e+00 - val_loss: 0.3891 - val_acc: 0.0000e+00\n",
      "Epoch 172/400\n",
      "80/80 [==============================] - 0s 342us/step - loss: 0.5270 - acc: 0.0000e+00 - val_loss: 0.3881 - val_acc: 0.0000e+00\n",
      "Epoch 173/400\n",
      "80/80 [==============================] - 0s 246us/step - loss: 0.5261 - acc: 0.0000e+00 - val_loss: 0.3872 - val_acc: 0.0000e+00\n",
      "Epoch 174/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.5251 - acc: 0.0000e+00 - val_loss: 0.3862 - val_acc: 0.0000e+00\n",
      "Epoch 175/400\n",
      "80/80 [==============================] - 0s 277us/step - loss: 0.5242 - acc: 0.0000e+00 - val_loss: 0.3853 - val_acc: 0.0000e+00\n",
      "Epoch 176/400\n",
      "80/80 [==============================] - 0s 213us/step - loss: 0.5232 - acc: 0.0000e+00 - val_loss: 0.3843 - val_acc: 0.0000e+00\n",
      "Epoch 177/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.5223 - acc: 0.0000e+00 - val_loss: 0.3833 - val_acc: 0.0000e+00\n",
      "Epoch 178/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5213 - acc: 0.0000e+00 - val_loss: 0.3823 - val_acc: 0.0000e+00\n",
      "Epoch 179/400\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.5203 - acc: 0.0000e+00 - val_loss: 0.3813 - val_acc: 0.0000e+00\n",
      "Epoch 180/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.5194 - acc: 0.0000e+00 - val_loss: 0.3803 - val_acc: 0.0000e+00\n",
      "Epoch 181/400\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.5184 - acc: 0.0000e+00 - val_loss: 0.3794 - val_acc: 0.0000e+00\n",
      "Epoch 182/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.5175 - acc: 0.0000e+00 - val_loss: 0.3784 - val_acc: 0.0000e+00\n",
      "Epoch 183/400\n",
      "80/80 [==============================] - 0s 716us/step - loss: 0.5164 - acc: 0.0000e+00 - val_loss: 0.3774 - val_acc: 0.0000e+00\n",
      "Epoch 184/400\n",
      "80/80 [==============================] - 0s 354us/step - loss: 0.5155 - acc: 0.0000e+00 - val_loss: 0.3764 - val_acc: 0.0000e+00\n",
      "Epoch 185/400\n",
      "80/80 [==============================] - 0s 210us/step - loss: 0.5146 - acc: 0.0000e+00 - val_loss: 0.3754 - val_acc: 0.0000e+00\n",
      "Epoch 186/400\n",
      "80/80 [==============================] - 0s 217us/step - loss: 0.5136 - acc: 0.0000e+00 - val_loss: 0.3744 - val_acc: 0.0000e+00\n",
      "Epoch 187/400\n",
      "80/80 [==============================] - 0s 252us/step - loss: 0.5127 - acc: 0.0000e+00 - val_loss: 0.3734 - val_acc: 0.0000e+00\n",
      "Epoch 188/400\n",
      "80/80 [==============================] - 0s 201us/step - loss: 0.5117 - acc: 0.0000e+00 - val_loss: 0.3725 - val_acc: 0.0000e+00\n",
      "Epoch 189/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.5107 - acc: 0.0000e+00 - val_loss: 0.3715 - val_acc: 0.0000e+00\n",
      "Epoch 190/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.5098 - acc: 0.0000e+00 - val_loss: 0.3704 - val_acc: 0.0000e+00\n",
      "Epoch 191/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.5088 - acc: 0.0000e+00 - val_loss: 0.3694 - val_acc: 0.0000e+00\n",
      "Epoch 192/400\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.5078 - acc: 0.0000e+00 - val_loss: 0.3684 - val_acc: 0.0000e+00\n",
      "Epoch 193/400\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.5068 - acc: 0.0000e+00 - val_loss: 0.3673 - val_acc: 0.0000e+00\n",
      "Epoch 194/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.5058 - acc: 0.0000e+00 - val_loss: 0.3662 - val_acc: 0.0000e+00\n",
      "Epoch 195/400\n",
      "80/80 [==============================] - 0s 205us/step - loss: 0.5049 - acc: 0.0000e+00 - val_loss: 0.3652 - val_acc: 0.0000e+00\n",
      "Epoch 196/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.5039 - acc: 0.0000e+00 - val_loss: 0.3641 - val_acc: 0.0000e+00\n",
      "Epoch 197/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.5029 - acc: 0.0000e+00 - val_loss: 0.3631 - val_acc: 0.0000e+00\n",
      "Epoch 198/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.5019 - acc: 0.0000e+00 - val_loss: 0.3620 - val_acc: 0.0000e+00\n",
      "Epoch 199/400\n",
      "80/80 [==============================] - 0s 284us/step - loss: 0.5009 - acc: 0.0000e+00 - val_loss: 0.3609 - val_acc: 0.0000e+00\n",
      "Epoch 200/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.4999 - acc: 0.0000e+00 - val_loss: 0.3598 - val_acc: 0.0000e+00\n",
      "Epoch 201/400\n",
      "80/80 [==============================] - 0s 268us/step - loss: 0.4989 - acc: 0.0000e+00 - val_loss: 0.3587 - val_acc: 0.0000e+00\n",
      "Epoch 202/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.4979 - acc: 0.0000e+00 - val_loss: 0.3576 - val_acc: 0.0000e+00\n",
      "Epoch 203/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.4969 - acc: 0.0000e+00 - val_loss: 0.3566 - val_acc: 0.0000e+00\n",
      "Epoch 204/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.4958 - acc: 0.0000e+00 - val_loss: 0.3556 - val_acc: 0.0000e+00\n",
      "Epoch 205/400\n",
      "80/80 [==============================] - 0s 247us/step - loss: 0.4947 - acc: 0.0000e+00 - val_loss: 0.3546 - val_acc: 0.0000e+00\n",
      "Epoch 206/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.4937 - acc: 0.0000e+00 - val_loss: 0.3536 - val_acc: 0.0000e+00\n",
      "Epoch 207/400\n",
      "80/80 [==============================] - 0s 217us/step - loss: 0.4926 - acc: 0.0000e+00 - val_loss: 0.3525 - val_acc: 0.0000e+00\n",
      "Epoch 208/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.4916 - acc: 0.0000e+00 - val_loss: 0.3515 - val_acc: 0.0000e+00\n",
      "Epoch 209/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.4904 - acc: 0.0000e+00 - val_loss: 0.3505 - val_acc: 0.0000e+00\n",
      "Epoch 210/400\n",
      "80/80 [==============================] - 0s 259us/step - loss: 0.4893 - acc: 0.0000e+00 - val_loss: 0.3494 - val_acc: 0.0000e+00\n",
      "Epoch 211/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4882 - acc: 0.0000e+00 - val_loss: 0.3483 - val_acc: 0.0000e+00\n",
      "Epoch 212/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.4871 - acc: 0.0000e+00 - val_loss: 0.3472 - val_acc: 0.0000e+00\n",
      "Epoch 213/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4860 - acc: 0.0000e+00 - val_loss: 0.3463 - val_acc: 0.0000e+00\n",
      "Epoch 214/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.4847 - acc: 0.0000e+00 - val_loss: 0.3453 - val_acc: 0.0000e+00\n",
      "Epoch 215/400\n",
      "80/80 [==============================] - 0s 205us/step - loss: 0.4836 - acc: 0.0000e+00 - val_loss: 0.3444 - val_acc: 0.0000e+00\n",
      "Epoch 216/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.4825 - acc: 0.0000e+00 - val_loss: 0.3434 - val_acc: 0.0000e+00\n",
      "Epoch 217/400\n",
      "80/80 [==============================] - 0s 235us/step - loss: 0.4812 - acc: 0.0000e+00 - val_loss: 0.3424 - val_acc: 0.0000e+00\n",
      "Epoch 218/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.4801 - acc: 0.0000e+00 - val_loss: 0.3414 - val_acc: 0.0000e+00\n",
      "Epoch 219/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4789 - acc: 0.0000e+00 - val_loss: 0.3404 - val_acc: 0.0000e+00\n",
      "Epoch 220/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.4776 - acc: 0.0000e+00 - val_loss: 0.3394 - val_acc: 0.0000e+00\n",
      "Epoch 221/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.4764 - acc: 0.0000e+00 - val_loss: 0.3383 - val_acc: 0.0000e+00\n",
      "Epoch 222/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.4752 - acc: 0.0000e+00 - val_loss: 0.3372 - val_acc: 0.0000e+00\n",
      "Epoch 223/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.4739 - acc: 0.0000e+00 - val_loss: 0.3362 - val_acc: 0.0000e+00\n",
      "Epoch 224/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.4727 - acc: 0.0000e+00 - val_loss: 0.3351 - val_acc: 0.0000e+00\n",
      "Epoch 225/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.4714 - acc: 0.0000e+00 - val_loss: 0.3340 - val_acc: 0.0000e+00\n",
      "Epoch 226/400\n",
      "80/80 [==============================] - 0s 277us/step - loss: 0.4701 - acc: 0.0000e+00 - val_loss: 0.3329 - val_acc: 0.0000e+00\n",
      "Epoch 227/400\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.4688 - acc: 0.0000e+00 - val_loss: 0.3318 - val_acc: 0.0000e+00\n",
      "Epoch 228/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 247us/step - loss: 0.4675 - acc: 0.0000e+00 - val_loss: 0.3308 - val_acc: 0.0000e+00\n",
      "Epoch 229/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.4662 - acc: 0.0000e+00 - val_loss: 0.3298 - val_acc: 0.0000e+00\n",
      "Epoch 230/400\n",
      "80/80 [==============================] - 0s 672us/step - loss: 0.4648 - acc: 0.0000e+00 - val_loss: 0.3288 - val_acc: 0.0000e+00\n",
      "Epoch 231/400\n",
      "80/80 [==============================] - 0s 319us/step - loss: 0.4635 - acc: 0.0000e+00 - val_loss: 0.3278 - val_acc: 0.0000e+00\n",
      "Epoch 232/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.4621 - acc: 0.0000e+00 - val_loss: 0.3268 - val_acc: 0.0000e+00\n",
      "Epoch 233/400\n",
      "80/80 [==============================] - 0s 203us/step - loss: 0.4607 - acc: 0.0000e+00 - val_loss: 0.3258 - val_acc: 0.0000e+00\n",
      "Epoch 234/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.4593 - acc: 0.0000e+00 - val_loss: 0.3248 - val_acc: 0.0000e+00\n",
      "Epoch 235/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.4579 - acc: 0.0000e+00 - val_loss: 0.3237 - val_acc: 0.0000e+00\n",
      "Epoch 236/400\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.4564 - acc: 0.0000e+00 - val_loss: 0.3226 - val_acc: 0.0000e+00\n",
      "Epoch 237/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.4550 - acc: 0.0000e+00 - val_loss: 0.3215 - val_acc: 0.0000e+00\n",
      "Epoch 238/400\n",
      "80/80 [==============================] - 0s 294us/step - loss: 0.4535 - acc: 0.0000e+00 - val_loss: 0.3204 - val_acc: 0.0000e+00\n",
      "Epoch 239/400\n",
      "80/80 [==============================] - 0s 245us/step - loss: 0.4520 - acc: 0.0000e+00 - val_loss: 0.3193 - val_acc: 0.0000e+00\n",
      "Epoch 240/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4506 - acc: 0.0000e+00 - val_loss: 0.3182 - val_acc: 0.0000e+00\n",
      "Epoch 241/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.4490 - acc: 0.0000e+00 - val_loss: 0.3170 - val_acc: 0.0000e+00\n",
      "Epoch 242/400\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.4474 - acc: 0.0000e+00 - val_loss: 0.3159 - val_acc: 0.0000e+00\n",
      "Epoch 243/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.4460 - acc: 0.0000e+00 - val_loss: 0.3147 - val_acc: 0.0000e+00\n",
      "Epoch 244/400\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.4443 - acc: 0.0000e+00 - val_loss: 0.3135 - val_acc: 0.0000e+00\n",
      "Epoch 245/400\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.4428 - acc: 0.0000e+00 - val_loss: 0.3123 - val_acc: 0.0000e+00\n",
      "Epoch 246/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.3854 - acc: 0.0000e+0 - 0s 316us/step - loss: 0.4413 - acc: 0.0000e+00 - val_loss: 0.3110 - val_acc: 0.0000e+00\n",
      "Epoch 247/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.4397 - acc: 0.0000e+00 - val_loss: 0.3098 - val_acc: 0.0000e+00\n",
      "Epoch 248/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.4379 - acc: 0.0000e+00 - val_loss: 0.3085 - val_acc: 0.0000e+00\n",
      "Epoch 249/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.4365 - acc: 0.0000e+00 - val_loss: 0.3072 - val_acc: 0.0000e+00\n",
      "Epoch 250/400\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.4348 - acc: 0.0000e+00 - val_loss: 0.3060 - val_acc: 0.0000e+00\n",
      "Epoch 251/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.4332 - acc: 0.0000e+00 - val_loss: 0.3047 - val_acc: 0.0000e+00\n",
      "Epoch 252/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.4316 - acc: 0.0000e+00 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 253/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.4298 - acc: 0.0000e+00 - val_loss: 0.3021 - val_acc: 0.0000e+00\n",
      "Epoch 254/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4282 - acc: 0.0000e+00 - val_loss: 0.3010 - val_acc: 0.0000e+00\n",
      "Epoch 255/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.4263 - acc: 0.0000e+00 - val_loss: 0.2998 - val_acc: 0.0000e+00\n",
      "Epoch 256/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.4246 - acc: 0.0000e+00 - val_loss: 0.2986 - val_acc: 0.0000e+00\n",
      "Epoch 257/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.4227 - acc: 0.0000e+00 - val_loss: 0.2974 - val_acc: 0.0000e+00\n",
      "Epoch 258/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.4209 - acc: 0.0000e+00 - val_loss: 0.2961 - val_acc: 0.0000e+00\n",
      "Epoch 259/400\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.4191 - acc: 0.0000e+00 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 260/400\n",
      "80/80 [==============================] - 0s 252us/step - loss: 0.4172 - acc: 0.0000e+00 - val_loss: 0.2936 - val_acc: 0.0000e+00\n",
      "Epoch 261/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.4153 - acc: 0.0000e+00 - val_loss: 0.2923 - val_acc: 0.0000e+00\n",
      "Epoch 262/400\n",
      "80/80 [==============================] - 0s 251us/step - loss: 0.4135 - acc: 0.0000e+00 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 263/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.4116 - acc: 0.0000e+00 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 264/400\n",
      "80/80 [==============================] - 0s 218us/step - loss: 0.4096 - acc: 0.0000e+00 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 265/400\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.4080 - acc: 0.0000e+00 - val_loss: 0.2870 - val_acc: 0.0000e+00\n",
      "Epoch 266/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 267/400\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.4040 - acc: 0.0000e+00 - val_loss: 0.2843 - val_acc: 0.0000e+00\n",
      "Epoch 268/400\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.4020 - acc: 0.0000e+00 - val_loss: 0.2829 - val_acc: 0.0000e+00\n",
      "Epoch 269/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.4002 - acc: 0.0000e+00 - val_loss: 0.2815 - val_acc: 0.0000e+00\n",
      "Epoch 270/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.3982 - acc: 0.0000e+00 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 271/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3962 - acc: 0.0000e+00 - val_loss: 0.2787 - val_acc: 0.0000e+00\n",
      "Epoch 272/400\n",
      "80/80 [==============================] - 0s 257us/step - loss: 0.3943 - acc: 0.0000e+00 - val_loss: 0.2774 - val_acc: 0.0000e+00\n",
      "Epoch 273/400\n",
      "80/80 [==============================] - 0s 253us/step - loss: 0.3922 - acc: 0.0000e+00 - val_loss: 0.2762 - val_acc: 0.0000e+00\n",
      "Epoch 274/400\n",
      "80/80 [==============================] - 0s 222us/step - loss: 0.3901 - acc: 0.0000e+00 - val_loss: 0.2750 - val_acc: 0.0000e+00\n",
      "Epoch 275/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.3881 - acc: 0.0000e+00 - val_loss: 0.2737 - val_acc: 0.0000e+00\n",
      "Epoch 276/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.3858 - acc: 0.0000e+00 - val_loss: 0.2724 - val_acc: 0.0000e+00\n",
      "Epoch 277/400\n",
      "80/80 [==============================] - 0s 663us/step - loss: 0.3839 - acc: 0.0000e+00 - val_loss: 0.2711 - val_acc: 0.0000e+00\n",
      "Epoch 278/400\n",
      "80/80 [==============================] - 0s 231us/step - loss: 0.3816 - acc: 0.0000e+00 - val_loss: 0.2698 - val_acc: 0.0000e+00\n",
      "Epoch 279/400\n",
      "80/80 [==============================] - 0s 321us/step - loss: 0.3795 - acc: 0.0000e+00 - val_loss: 0.2684 - val_acc: 0.0000e+00\n",
      "Epoch 280/400\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.3775 - acc: 0.0000e+00 - val_loss: 0.2673 - val_acc: 0.0000e+00\n",
      "Epoch 281/400\n",
      "80/80 [==============================] - 0s 247us/step - loss: 0.3751 - acc: 0.0000e+00 - val_loss: 0.2663 - val_acc: 0.0000e+00\n",
      "Epoch 282/400\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.3729 - acc: 0.0000e+00 - val_loss: 0.2652 - val_acc: 0.0000e+00\n",
      "Epoch 283/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3705 - acc: 0.0000e+00 - val_loss: 0.2641 - val_acc: 0.0000e+00\n",
      "Epoch 284/400\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.3684 - acc: 0.0000e+00 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 285/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 236us/step - loss: 0.3659 - acc: 0.0000e+00 - val_loss: 0.2618 - val_acc: 0.0000e+00\n",
      "Epoch 286/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.3636 - acc: 0.0000e+00 - val_loss: 0.2607 - val_acc: 0.0000e+00\n",
      "Epoch 287/400\n",
      "80/80 [==============================] - 0s 264us/step - loss: 0.3616 - acc: 0.0000e+00 - val_loss: 0.2595 - val_acc: 0.0000e+00\n",
      "Epoch 288/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.3593 - acc: 0.0000e+00 - val_loss: 0.2583 - val_acc: 0.0000e+00\n",
      "Epoch 289/400\n",
      "80/80 [==============================] - 0s 219us/step - loss: 0.3568 - acc: 0.0000e+00 - val_loss: 0.2571 - val_acc: 0.0000e+00\n",
      "Epoch 290/400\n",
      "80/80 [==============================] - 0s 216us/step - loss: 0.3545 - acc: 0.0000e+00 - val_loss: 0.2560 - val_acc: 0.0000e+00\n",
      "Epoch 291/400\n",
      "80/80 [==============================] - 0s 220us/step - loss: 0.3522 - acc: 0.0000e+00 - val_loss: 0.2551 - val_acc: 0.0000e+00\n",
      "Epoch 292/400\n",
      "80/80 [==============================] - 0s 303us/step - loss: 0.3498 - acc: 0.0000e+00 - val_loss: 0.2542 - val_acc: 0.0000e+00\n",
      "Epoch 293/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.3473 - acc: 0.0000e+00 - val_loss: 0.2532 - val_acc: 0.0000e+00\n",
      "Epoch 294/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.3448 - acc: 0.0000e+00 - val_loss: 0.2523 - val_acc: 0.0000e+00\n",
      "Epoch 295/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.3425 - acc: 0.0000e+00 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 296/400\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.3399 - acc: 0.0000e+00 - val_loss: 0.2503 - val_acc: 0.0000e+00\n",
      "Epoch 297/400\n",
      "80/80 [==============================] - 0s 273us/step - loss: 0.3374 - acc: 0.0000e+00 - val_loss: 0.2493 - val_acc: 0.0000e+00\n",
      "Epoch 298/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3350 - acc: 0.0000e+00 - val_loss: 0.2482 - val_acc: 0.0000e+00\n",
      "Epoch 299/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3326 - acc: 0.0000e+00 - val_loss: 0.2472 - val_acc: 0.0000e+00\n",
      "Epoch 300/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.3300 - acc: 0.0000e+00 - val_loss: 0.2461 - val_acc: 0.0000e+00\n",
      "Epoch 301/400\n",
      "80/80 [==============================] - 0s 269us/step - loss: 0.3279 - acc: 0.0000e+00 - val_loss: 0.2451 - val_acc: 0.0000e+00\n",
      "Epoch 302/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3253 - acc: 0.0000e+00 - val_loss: 0.2440 - val_acc: 0.0000e+00\n",
      "Epoch 303/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.3228 - acc: 0.0000e+00 - val_loss: 0.2429 - val_acc: 0.0000e+00\n",
      "Epoch 304/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.3204 - acc: 0.0000e+00 - val_loss: 0.2417 - val_acc: 0.0000e+00\n",
      "Epoch 305/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.3180 - acc: 0.0000e+00 - val_loss: 0.2406 - val_acc: 0.0000e+00\n",
      "Epoch 306/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.3156 - acc: 0.0000e+00 - val_loss: 0.2395 - val_acc: 0.0000e+00\n",
      "Epoch 307/400\n",
      "80/80 [==============================] - 0s 233us/step - loss: 0.3133 - acc: 0.0000e+00 - val_loss: 0.2384 - val_acc: 0.0000e+00\n",
      "Epoch 308/400\n",
      "80/80 [==============================] - 0s 248us/step - loss: 0.3111 - acc: 0.0000e+00 - val_loss: 0.2374 - val_acc: 0.0000e+00\n",
      "Epoch 309/400\n",
      "80/80 [==============================] - 0s 264us/step - loss: 0.3086 - acc: 0.0000e+00 - val_loss: 0.2366 - val_acc: 0.0000e+00\n",
      "Epoch 310/400\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.3065 - acc: 0.0000e+00 - val_loss: 0.2358 - val_acc: 0.0000e+00\n",
      "Epoch 311/400\n",
      "80/80 [==============================] - 0s 223us/step - loss: 0.3041 - acc: 0.0000e+00 - val_loss: 0.2350 - val_acc: 0.0000e+00\n",
      "Epoch 312/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.3017 - acc: 0.0000e+00 - val_loss: 0.2342 - val_acc: 0.0000e+00\n",
      "Epoch 313/400\n",
      "80/80 [==============================] - 0s 256us/step - loss: 0.2995 - acc: 0.0000e+00 - val_loss: 0.2334 - val_acc: 0.0000e+00\n",
      "Epoch 314/400\n",
      "80/80 [==============================] - 0s 267us/step - loss: 0.2972 - acc: 0.0000e+00 - val_loss: 0.2330 - val_acc: 0.0000e+00\n",
      "Epoch 315/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.2950 - acc: 0.0000e+00 - val_loss: 0.2326 - val_acc: 0.0000e+00\n",
      "Epoch 316/400\n",
      "80/80 [==============================] - 0s 245us/step - loss: 0.2925 - acc: 0.0000e+00 - val_loss: 0.2321 - val_acc: 0.0000e+00\n",
      "Epoch 317/400\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.2903 - acc: 0.0000e+00 - val_loss: 0.2317 - val_acc: 0.0000e+00\n",
      "Epoch 318/400\n",
      "80/80 [==============================] - 0s 276us/step - loss: 0.2883 - acc: 0.0000e+00 - val_loss: 0.2312 - val_acc: 0.0000e+00\n",
      "Epoch 319/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.2858 - acc: 0.0000e+00 - val_loss: 0.2307 - val_acc: 0.0000e+00\n",
      "Epoch 320/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.2836 - acc: 0.0000e+00 - val_loss: 0.2303 - val_acc: 0.0000e+00\n",
      "Epoch 321/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.2814 - acc: 0.0000e+00 - val_loss: 0.2298 - val_acc: 0.0000e+00\n",
      "Epoch 322/400\n",
      "80/80 [==============================] - 0s 297us/step - loss: 0.2791 - acc: 0.0000e+00 - val_loss: 0.2293 - val_acc: 0.0000e+00\n",
      "Epoch 323/400\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.2770 - acc: 0.0000e+00 - val_loss: 0.2288 - val_acc: 0.0000e+00\n",
      "Epoch 324/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2751 - acc: 0.0000e+00 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 325/400\n",
      "80/80 [==============================] - 0s 361us/step - loss: 0.2730 - acc: 0.0000e+00 - val_loss: 0.2283 - val_acc: 0.0000e+00\n",
      "Epoch 326/400\n",
      "80/80 [==============================] - 0s 346us/step - loss: 0.2708 - acc: 0.0000e+00 - val_loss: 0.2282 - val_acc: 0.0000e+00\n",
      "Epoch 327/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.2687 - acc: 0.0000e+00 - val_loss: 0.2281 - val_acc: 0.0000e+00\n",
      "Epoch 328/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.2668 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 329/400\n",
      "80/80 [==============================] - 0s 244us/step - loss: 0.2646 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0000e+00\n",
      "Epoch 330/400\n",
      "80/80 [==============================] - 0s 182us/step - loss: 0.2628 - acc: 0.0000e+00 - val_loss: 0.2282 - val_acc: 0.0000e+00\n",
      "Epoch 331/400\n",
      "80/80 [==============================] - 0s 332us/step - loss: 0.2607 - acc: 0.0000e+00 - val_loss: 0.2285 - val_acc: 0.0000e+00\n",
      "Epoch 332/400\n",
      "80/80 [==============================] - 0s 211us/step - loss: 0.2587 - acc: 0.0000e+00 - val_loss: 0.2287 - val_acc: 0.0000e+00\n",
      "Epoch 333/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.2570 - acc: 0.0000e+00 - val_loss: 0.2290 - val_acc: 0.0000e+00\n",
      "Epoch 334/400\n",
      "80/80 [==============================] - 0s 314us/step - loss: 0.2551 - acc: 0.0000e+00 - val_loss: 0.2292 - val_acc: 0.0000e+00\n",
      "Epoch 335/400\n",
      "80/80 [==============================] - 0s 236us/step - loss: 0.2534 - acc: 0.0000e+00 - val_loss: 0.2293 - val_acc: 0.0500\n",
      "Epoch 336/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.2519 - acc: 0.0000e+00 - val_loss: 0.2295 - val_acc: 0.0500\n",
      "Epoch 337/400\n",
      "80/80 [==============================] - 0s 248us/step - loss: 0.2501 - acc: 0.0000e+00 - val_loss: 0.2296 - val_acc: 0.0500\n",
      "Epoch 338/400\n",
      "80/80 [==============================] - 0s 270us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.2297 - val_acc: 0.0500\n",
      "Epoch 339/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2473 - acc: 0.0000e+00 - val_loss: 0.2298 - val_acc: 0.0500\n",
      "Epoch 340/400\n",
      "80/80 [==============================] - 0s 239us/step - loss: 0.2457 - acc: 0.0000e+00 - val_loss: 0.2301 - val_acc: 0.0500\n",
      "Epoch 341/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.2442 - acc: 0.0000e+00 - val_loss: 0.2305 - val_acc: 0.0500\n",
      "Epoch 342/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 278us/step - loss: 0.2428 - acc: 0.0000e+00 - val_loss: 0.2308 - val_acc: 0.0500\n",
      "Epoch 343/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.2413 - acc: 0.0000e+00 - val_loss: 0.2311 - val_acc: 0.0500\n",
      "Epoch 344/400\n",
      "80/80 [==============================] - 0s 229us/step - loss: 0.2401 - acc: 0.0000e+00 - val_loss: 0.2315 - val_acc: 0.0500\n",
      "Epoch 345/400\n",
      "80/80 [==============================] - 0s 270us/step - loss: 0.2388 - acc: 0.0000e+00 - val_loss: 0.2318 - val_acc: 0.0500\n",
      "Epoch 346/400\n",
      "80/80 [==============================] - 0s 232us/step - loss: 0.2375 - acc: 0.0000e+00 - val_loss: 0.2322 - val_acc: 0.0500\n",
      "Epoch 347/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.2363 - acc: 0.0000e+00 - val_loss: 0.2325 - val_acc: 0.0500\n",
      "Epoch 348/400\n",
      "80/80 [==============================] - 0s 248us/step - loss: 0.2351 - acc: 0.0000e+00 - val_loss: 0.2328 - val_acc: 0.0500\n",
      "Epoch 349/400\n",
      "80/80 [==============================] - 0s 253us/step - loss: 0.2338 - acc: 0.0000e+00 - val_loss: 0.2331 - val_acc: 0.0500\n",
      "Epoch 350/400\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.2326 - acc: 0.0000e+00 - val_loss: 0.2334 - val_acc: 0.0500\n",
      "Epoch 351/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.2316 - acc: 0.0000e+00 - val_loss: 0.2337 - val_acc: 0.0500\n",
      "Epoch 352/400\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.2305 - acc: 0.0000e+00 - val_loss: 0.2340 - val_acc: 0.0500\n",
      "Epoch 353/400\n",
      "80/80 [==============================] - 0s 264us/step - loss: 0.2295 - acc: 0.0000e+00 - val_loss: 0.2343 - val_acc: 0.0500\n",
      "Epoch 354/400\n",
      "80/80 [==============================] - 0s 259us/step - loss: 0.2284 - acc: 0.0000e+00 - val_loss: 0.2346 - val_acc: 0.0500\n",
      "Epoch 355/400\n",
      "80/80 [==============================] - 0s 264us/step - loss: 0.2276 - acc: 0.0000e+00 - val_loss: 0.2349 - val_acc: 0.0500\n",
      "Epoch 356/400\n",
      "80/80 [==============================] - 0s 251us/step - loss: 0.2267 - acc: 0.0000e+00 - val_loss: 0.2351 - val_acc: 0.0500\n",
      "Epoch 357/400\n",
      "80/80 [==============================] - 0s 246us/step - loss: 0.2257 - acc: 0.0000e+00 - val_loss: 0.2352 - val_acc: 0.0500\n",
      "Epoch 358/400\n",
      "80/80 [==============================] - 0s 275us/step - loss: 0.2248 - acc: 0.0000e+00 - val_loss: 0.2353 - val_acc: 0.0500\n",
      "Epoch 359/400\n",
      "80/80 [==============================] - 0s 260us/step - loss: 0.2241 - acc: 0.0000e+00 - val_loss: 0.2356 - val_acc: 0.0500\n",
      "Epoch 360/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.2232 - acc: 0.0000e+00 - val_loss: 0.2360 - val_acc: 0.0500\n",
      "Epoch 361/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.2224 - acc: 0.0000e+00 - val_loss: 0.2365 - val_acc: 0.0500\n",
      "Epoch 362/400\n",
      "80/80 [==============================] - 0s 293us/step - loss: 0.2217 - acc: 0.0000e+00 - val_loss: 0.2369 - val_acc: 0.0500\n",
      "Epoch 363/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2209 - acc: 0.0000e+00 - val_loss: 0.2374 - val_acc: 0.0500\n",
      "Epoch 364/400\n",
      "80/80 [==============================] - 0s 284us/step - loss: 0.2200 - acc: 0.0000e+00 - val_loss: 0.2380 - val_acc: 0.0500\n",
      "Epoch 365/400\n",
      "80/80 [==============================] - 0s 260us/step - loss: 0.2192 - acc: 0.0000e+00 - val_loss: 0.2385 - val_acc: 0.0500\n",
      "Epoch 366/400\n",
      "80/80 [==============================] - 0s 253us/step - loss: 0.2185 - acc: 0.0000e+00 - val_loss: 0.2392 - val_acc: 0.0500\n",
      "Epoch 367/400\n",
      "80/80 [==============================] - 0s 243us/step - loss: 0.2177 - acc: 0.0000e+00 - val_loss: 0.2398 - val_acc: 0.0500\n",
      "Epoch 368/400\n",
      "80/80 [==============================] - 0s 692us/step - loss: 0.2171 - acc: 0.0000e+00 - val_loss: 0.2404 - val_acc: 0.0500\n",
      "Epoch 369/400\n",
      "80/80 [==============================] - 0s 396us/step - loss: 0.2163 - acc: 0.0000e+00 - val_loss: 0.2408 - val_acc: 0.0500\n",
      "Epoch 370/400\n",
      "80/80 [==============================] - 0s 246us/step - loss: 0.2156 - acc: 0.0000e+00 - val_loss: 0.2412 - val_acc: 0.0500\n",
      "Epoch 371/400\n",
      "80/80 [==============================] - 0s 253us/step - loss: 0.2150 - acc: 0.0000e+00 - val_loss: 0.2417 - val_acc: 0.0500\n",
      "Epoch 372/400\n",
      "80/80 [==============================] - 0s 271us/step - loss: 0.2144 - acc: 0.0000e+00 - val_loss: 0.2420 - val_acc: 0.0500\n",
      "Epoch 373/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.2138 - acc: 0.0000e+00 - val_loss: 0.2423 - val_acc: 0.0500\n",
      "Epoch 374/400\n",
      "80/80 [==============================] - 0s 242us/step - loss: 0.2133 - acc: 0.0000e+00 - val_loss: 0.2425 - val_acc: 0.0500\n",
      "Epoch 375/400\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.2128 - acc: 0.0000e+00 - val_loss: 0.2427 - val_acc: 0.0500\n",
      "Epoch 376/400\n",
      "80/80 [==============================] - 0s 259us/step - loss: 0.2122 - acc: 0.0000e+00 - val_loss: 0.2429 - val_acc: 0.0500\n",
      "Epoch 377/400\n",
      "80/80 [==============================] - 0s 341us/step - loss: 0.2118 - acc: 0.0000e+00 - val_loss: 0.2431 - val_acc: 0.0500\n",
      "Epoch 378/400\n",
      "80/80 [==============================] - 0s 273us/step - loss: 0.2113 - acc: 0.0000e+00 - val_loss: 0.2434 - val_acc: 0.0500\n",
      "Epoch 379/400\n",
      "80/80 [==============================] - 0s 285us/step - loss: 0.2107 - acc: 0.0000e+00 - val_loss: 0.2436 - val_acc: 0.0500\n",
      "Epoch 380/400\n",
      "80/80 [==============================] - 0s 419us/step - loss: 0.2103 - acc: 0.0000e+00 - val_loss: 0.2438 - val_acc: 0.0500\n",
      "Epoch 381/400\n",
      "80/80 [==============================] - 0s 385us/step - loss: 0.2099 - acc: 0.0000e+00 - val_loss: 0.2441 - val_acc: 0.0500\n",
      "Epoch 382/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.2094 - acc: 0.0000e+00 - val_loss: 0.2444 - val_acc: 0.0500\n",
      "Epoch 383/400\n",
      "80/80 [==============================] - 0s 327us/step - loss: 0.2089 - acc: 0.0000e+00 - val_loss: 0.2446 - val_acc: 0.0500\n",
      "Epoch 384/400\n",
      "80/80 [==============================] - 0s 261us/step - loss: 0.2085 - acc: 0.0000e+00 - val_loss: 0.2447 - val_acc: 0.0500\n",
      "Epoch 385/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.2081 - acc: 0.0000e+00 - val_loss: 0.2448 - val_acc: 0.0500\n",
      "Epoch 386/400\n",
      "80/80 [==============================] - 0s 257us/step - loss: 0.2077 - acc: 0.0000e+00 - val_loss: 0.2448 - val_acc: 0.0500\n",
      "Epoch 387/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2073 - acc: 0.0000e+00 - val_loss: 0.2449 - val_acc: 0.0500\n",
      "Epoch 388/400\n",
      "80/80 [==============================] - 0s 226us/step - loss: 0.2069 - acc: 0.0000e+00 - val_loss: 0.2450 - val_acc: 0.0500\n",
      "Epoch 389/400\n",
      "80/80 [==============================] - 0s 214us/step - loss: 0.2065 - acc: 0.0000e+00 - val_loss: 0.2450 - val_acc: 0.0500\n",
      "Epoch 390/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.2061 - acc: 0.0000e+00 - val_loss: 0.2450 - val_acc: 0.0500\n",
      "Epoch 391/400\n",
      "80/80 [==============================] - 0s 285us/step - loss: 0.2057 - acc: 0.0000e+00 - val_loss: 0.2450 - val_acc: 0.0500\n",
      "Epoch 392/400\n",
      "80/80 [==============================] - 0s 256us/step - loss: 0.2054 - acc: 0.0000e+00 - val_loss: 0.2451 - val_acc: 0.0500\n",
      "Epoch 393/400\n",
      "80/80 [==============================] - 0s 245us/step - loss: 0.2050 - acc: 0.0000e+00 - val_loss: 0.2452 - val_acc: 0.0500\n",
      "Epoch 394/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.2047 - acc: 0.0000e+00 - val_loss: 0.2452 - val_acc: 0.0500\n",
      "Epoch 395/400\n",
      "80/80 [==============================] - 0s 254us/step - loss: 0.2043 - acc: 0.0000e+00 - val_loss: 0.2452 - val_acc: 0.0500\n",
      "Epoch 396/400\n",
      "80/80 [==============================] - 0s 228us/step - loss: 0.2040 - acc: 0.0000e+00 - val_loss: 0.2452 - val_acc: 0.0500\n",
      "Epoch 397/400\n",
      "80/80 [==============================] - 0s 257us/step - loss: 0.2037 - acc: 0.0000e+00 - val_loss: 0.2451 - val_acc: 0.0500\n",
      "Epoch 398/400\n",
      "80/80 [==============================] - 0s 230us/step - loss: 0.2034 - acc: 0.0000e+00 - val_loss: 0.2449 - val_acc: 0.0500\n",
      "Epoch 399/400\n",
      "80/80 [==============================] - 0s 248us/step - loss: 0.2030 - acc: 0.0000e+00 - val_loss: 0.2449 - val_acc: 0.0500\n",
      "Epoch 400/400\n",
      "80/80 [==============================] - 0s 238us/step - loss: 0.2027 - acc: 0.0000e+00 - val_loss: 0.2447 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=400,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:50.010244Z",
     "start_time": "2019-08-11T17:00:49.906274Z"
    }
   },
   "outputs": [],
   "source": [
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:50.184976Z",
     "start_time": "2019-08-11T17:00:50.012300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20), results, c='r')\n",
    "plt.scatter(range(20), y_test, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T17:00:50.450341Z",
     "start_time": "2019-08-11T17:00:50.194004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
