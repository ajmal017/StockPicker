{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.249153Z",
     "start_time": "2019-10-05T02:36:40.922340Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request, json , time, os, difflib, itertools\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.258136Z",
     "start_time": "2019-10-05T02:36:41.251656Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import httplib\n",
    "except:\n",
    "    import http.client as httplib\n",
    "\n",
    "def check_internet():\n",
    "    conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)\n",
    "    try:\n",
    "        conn.request(\"HEAD\", \"/\")\n",
    "        conn.close()\n",
    "        print(\"True\")\n",
    "        return True\n",
    "    except:\n",
    "        conn.close()\n",
    "        print(\"False\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.293614Z",
     "start_time": "2019-10-05T02:36:41.260197Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_historic_price(query_url,json_path,csv_path):\n",
    "    \n",
    "    while not check_internet():\n",
    "        print(\"Could not connect, trying again in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "    \n",
    "    stock_id=query_url.split(\"&period\")[0].split(\"symbol=\")[1]\n",
    "    \n",
    "    if os.path.exists(csv_path+stock_id+'.csv') and os.stat(csv_path+stock_id+'.csv').st_size != 0:\n",
    "        print(\"<<<  Historical data of \"+stock_id+\" already exists, Updating data...\")\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(query_url) as url:\n",
    "                parsed = json.loads(url.read().decode())\n",
    "        except:\n",
    "            print(\"|||  Historical data of \"+stock_id+\" doesn't exist\")\n",
    "            return\n",
    "    \n",
    "    else:\n",
    "        if os.path.exists(json_path+stock_id+'.json'):\n",
    "            os.remove(json_path+stock_id+'.json')\n",
    "        with open(json_path+stock_id+'.json', 'w') as outfile:\n",
    "            json.dump(parsed, outfile, indent=4)\n",
    "\n",
    "        try:\n",
    "            Date=[]\n",
    "            for i in parsed['chart']['result'][0]['timestamp']:\n",
    "                Date.append(datetime.utcfromtimestamp(int(i)).strftime('%d-%m-%Y'))\n",
    "\n",
    "            Low=parsed['chart']['result'][0]['indicators']['quote'][0]['low']\n",
    "            Open=parsed['chart']['result'][0]['indicators']['quote'][0]['open']\n",
    "            Volume=parsed['chart']['result'][0]['indicators']['quote'][0]['volume']\n",
    "            High=parsed['chart']['result'][0]['indicators']['quote'][0]['high']\n",
    "            Close=parsed['chart']['result'][0]['indicators']['quote'][0]['close']\n",
    "            Adjusted_Close=parsed['chart']['result'][0]['indicators']['adjclose'][0]['adjclose']\n",
    "\n",
    "            df=pd.DataFrame(list(zip(Date,Low,Open,Volume,High,Close,Adjusted_Close)),columns =['Date','Low','Open','Volume','High','Close','Adjusted Close'])\n",
    "\n",
    "            if os.path.exists(csv_path+stock_id+'.csv'):\n",
    "                os.remove(csv_path+stock_id+'.csv')\n",
    "            df.to_csv(csv_path+stock_id+'.csv', sep=',', index=None)\n",
    "            print(\">>>  Historical data of \"+stock_id+\" saved\")\n",
    "            return\n",
    "        except:\n",
    "            print(\">>>  Historical data of \"+stock_id+\" exists but has no trading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.300299Z",
     "start_time": "2019-10-05T02:36:41.296467Z"
    }
   },
   "outputs": [],
   "source": [
    "json_path = os.getcwd()+os.sep+\"..\"+os.sep+\"Data\"+os.sep+\"json\"+os.sep\n",
    "csv_path = os.getcwd()+os.sep+\"..\"+os.sep+\"Data\"+os.sep+\"csv\"+os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.308455Z",
     "start_time": "2019-10-05T02:36:41.302662Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(json_path):\n",
    "    os.makedirs(json_path)\n",
    "if not os.path.isdir(csv_path):\n",
    "    os.makedirs(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:41.316098Z",
     "start_time": "2019-10-05T02:36:41.311316Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tickers_from_2017(country_name):\n",
    "    ticker_file_path = \"Assets\"+os.sep+\"Yahoo Ticker Symbols - September 2017.xlsx\"\n",
    "    df = pd.read_excel(ticker_file_path)\n",
    "    \n",
    "    df = df.drop(df.columns[[5, 6, 7]], axis=1)\n",
    "    headers = df.iloc[2]\n",
    "    df  = pd.DataFrame(df.values[3:], columns=headers)\n",
    "    \n",
    "    df = df[df[\"Country\"].str.lower().str.contains(country_name.lower()) == True]\n",
    "    print(\"Total stocks:\",len(df))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.054579Z",
     "start_time": "2019-10-05T02:36:41.317938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stocks: 22169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OEDV</td>\n",
       "      <td>Osage Exploration and Development, Inc.</td>\n",
       "      <td>PNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>NMS</td>\n",
       "      <td>Electronic Equipment</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>Money Center Banks</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>NMS</td>\n",
       "      <td>Catalog &amp; Mail Order Houses</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>Telecom Services - Domestic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2 Ticker                                     Name Exchange  \\\n",
       "0   OEDV  Osage Exploration and Development, Inc.      PNK   \n",
       "1   AAPL                               Apple Inc.      NMS   \n",
       "2    BAC              Bank of America Corporation      NYQ   \n",
       "3   AMZN                         Amazon.com, Inc.      NMS   \n",
       "4      T                                AT&T Inc.      NYQ   \n",
       "\n",
       "2                Category Name Country  \n",
       "0                          NaN     USA  \n",
       "1         Electronic Equipment     USA  \n",
       "2           Money Center Banks     USA  \n",
       "3  Catalog & Mail Order Houses     USA  \n",
       "4  Telecom Services - Domestic     USA  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_name = \"USA\"\n",
    "us_2017_tickers = get_tickers_from_2017(country_name)\n",
    "us_2017_tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.171267Z",
     "start_time": "2019-10-05T02:36:53.060691Z"
    }
   },
   "outputs": [],
   "source": [
    "us_2017_tickers.to_csv( os.getcwd()+os.sep+\"..\"+os.sep+\"Data\"+os.sep+country_name+'.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.351991Z",
     "start_time": "2019-10-05T02:36:53.174367Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tickers_from_names(company_list, df):\n",
    "    ticker_list=[]\n",
    "    for company in company_list:\n",
    "        try:\n",
    "            exact_company_name = (difflib.get_close_matches(company, df['Name'])[0])\n",
    "            ticker_for_the_company = df.loc[df['Name'] == exact_company_name, 'Ticker'].iloc[0]\n",
    "            ticker_list.append(ticker_for_the_company)\n",
    "        except:\n",
    "            print(\"Company name \"+company+\" not found.\")\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.360154Z",
     "start_time": "2019-10-05T02:36:53.353671Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_query_list(ticker_list):\n",
    "    query_urls=[]\n",
    "    for ticker in ticker_list:\n",
    "        query_urls.append(\"https://query1.finance.yahoo.com/v8/finance/chart/\"+ticker+\"?symbol=\"+ticker+\n",
    "                          \"&period1=0&period2=9999999999&interval=5d&includePrePost=true&events=div%2Csplit\")\n",
    "    return query_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.372876Z",
     "start_time": "2019-10-05T02:36:53.362812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OEDV</td>\n",
       "      <td>Osage Exploration and Development, Inc.</td>\n",
       "      <td>PNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>NMS</td>\n",
       "      <td>Electronic Equipment</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>Money Center Banks</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>NMS</td>\n",
       "      <td>Catalog &amp; Mail Order Houses</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>Telecom Services - Domestic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2 Ticker                                     Name Exchange  \\\n",
       "0   OEDV  Osage Exploration and Development, Inc.      PNK   \n",
       "1   AAPL                               Apple Inc.      NMS   \n",
       "2    BAC              Bank of America Corporation      NYQ   \n",
       "3   AMZN                         Amazon.com, Inc.      NMS   \n",
       "4      T                                AT&T Inc.      NYQ   \n",
       "\n",
       "2                Category Name Country  \n",
       "0                          NaN     USA  \n",
       "1         Electronic Equipment     USA  \n",
       "2           Money Center Banks     USA  \n",
       "3  Catalog & Mail Order Houses     USA  \n",
       "4  Telecom Services - Domestic     USA  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potential queries\n",
    "\n",
    "# https://query1.finance.yahoo.com/v8/finance/chart/%5EGSPC?p=^GSPC\n",
    "# https://query1.finance.yahoo.com/v8/finance/chart/AAPL?symbol=AAPL&period1=0&period2=9999999999&interval=1d&includePrePost=true&events=div%2Csplit\n",
    "# https://query1.finance.yahoo.com/v8/finance/chart/%5EGSPC?p=^GSPC&period1=0&period2=9999999999&interval=1wk&includePrePost=true&events=div%2Csplit\n",
    "\n",
    "us_2017_tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.378470Z",
     "start_time": "2019-10-05T02:36:53.374834Z"
    }
   },
   "outputs": [],
   "source": [
    "queries = ['https://query1.finance.yahoo.com/v8/finance/chart/%5EGSPC?p=^GSPC&period1=0&period2=9999999999&interval=1wk&includePrePost=true&events=div%2Csplit']\n",
    "desired_company_list = [ 'Apple Inc.', 'Amazon.com, Inc.', 'Alphabet Inc.' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.724362Z",
     "start_time": "2019-10-05T02:36:53.380612Z"
    }
   },
   "outputs": [],
   "source": [
    "queries += get_query_list(get_tickers_from_names(desired_company_list, us_2017_tickers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:53.729381Z",
     "start_time": "2019-10-05T02:36:53.726085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://query1.finance.yahoo.com/v8/finance/chart/%5EGSPC?p=^GSPC&period1=0&period2=9999999999&interval=1wk&includePrePost=true&events=div%2Csplit', 'https://query1.finance.yahoo.com/v8/finance/chart/AAPL?symbol=AAPL&period1=0&period2=9999999999&interval=5d&includePrePost=true&events=div%2Csplit', 'https://query1.finance.yahoo.com/v8/finance/chart/AMZN?symbol=AMZN&period1=0&period2=9999999999&interval=5d&includePrePost=true&events=div%2Csplit', 'https://query1.finance.yahoo.com/v8/finance/chart/GOOG?symbol=GOOG&period1=0&period2=9999999999&interval=5d&includePrePost=true&events=div%2Csplit']\n"
     ]
    }
   ],
   "source": [
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_price(query_url,json_path,csv_path):\n",
    "    \n",
    "    while not check_internet():\n",
    "        print(\"Could not connect, trying again in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "    \n",
    "    stock_id=query_url.split(\"&period\")[0].split(\"symbol=\")[1]\n",
    "    \n",
    "    if os.path.exists(csv_path+stock_id+'.csv') and os.stat(csv_path+stock_id+'.csv').st_size != 0:\n",
    "        print(\"<<<  Historical data of \"+stock_id+\" already exists, Updating data...\")\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(query_url) as url:\n",
    "                parsed = json.loads(url.read().decode())\n",
    "        except:\n",
    "            print(\"|||  Historical data of \"+stock_id+\" doesn't exist\")\n",
    "            return\n",
    "    \n",
    "    else:\n",
    "        if os.path.exists(json_path+stock_id+'.json'):\n",
    "            os.remove(json_path+stock_id+'.json')\n",
    "        with open(json_path+stock_id+'.json', 'w') as outfile:\n",
    "            json.dump(parsed, outfile, indent=4)\n",
    "\n",
    "        try:\n",
    "            Date=[]\n",
    "            for i in parsed['chart']['result'][0]['timestamp']:\n",
    "                Date.append(datetime.utcfromtimestamp(int(i)).strftime('%d-%m-%Y'))\n",
    "\n",
    "            Low=parsed['chart']['result'][0]['indicators']['quote'][0]['low']\n",
    "            Open=parsed['chart']['result'][0]['indicators']['quote'][0]['open']\n",
    "            Volume=parsed['chart']['result'][0]['indicators']['quote'][0]['volume']\n",
    "            High=parsed['chart']['result'][0]['indicators']['quote'][0]['high']\n",
    "            Close=parsed['chart']['result'][0]['indicators']['quote'][0]['close']\n",
    "            Adjusted_Close=parsed['chart']['result'][0]['indicators']['adjclose'][0]['adjclose']\n",
    "\n",
    "            df=pd.DataFrame(list(zip(Date,Low,Open,Volume,High,Close,Adjusted_Close)),columns =['Date','Low','Open','Volume','High','Close','Adjusted Close'])\n",
    "\n",
    "            if os.path.exists(csv_path+stock_id+'.csv'):\n",
    "                os.remove(csv_path+stock_id+'.csv')\n",
    "            df.to_csv(csv_path+stock_id+'.csv', sep=',', index=None)\n",
    "            print(\">>>  Historical data of \"+stock_id+\" saved\")\n",
    "            return\n",
    "        except:\n",
    "            print(\">>>  Historical data of \"+stock_id+\" exists but has no trading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T02:36:54.132577Z",
     "start_time": "2019-10-05T02:36:53.732351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-164a84c75ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_historic_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All downloads completed !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         '''\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bea44fcaf9ec>\u001b[0m in \u001b[0;36mget_historic_price\u001b[0;34m(query_url, json_path, csv_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mstock_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&period\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"symbol=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstock_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstock_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with Pool(processes=len(queries)) as pool:\n",
    "    pool.starmap(get_historic_price, zip(queries, itertools.repeat(json_path), itertools.repeat(csv_path)))\n",
    "print(\"All downloads completed !\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
